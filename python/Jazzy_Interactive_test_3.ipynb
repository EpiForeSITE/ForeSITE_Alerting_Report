{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c646c7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taohe\\miniconda3\\envs\\epysurv-dev\\lib\\site-packages\\rpy2\\robjects\\pandas2ri.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from epysurv.models.timepoint import FarringtonFlexible\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import requests\n",
    "from sodapy import Socrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56317acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getCdcData(where=None, select=None):\n",
    "    try:\n",
    "        app_token=\"Wa9PucgUy1cHNJgzoTZwhg9AY\"\n",
    "        client = Socrata(\"data.cdc.gov\", app_token=app_token, timeout=120)\n",
    "        \n",
    "        all_results = []\n",
    "        offset = 0\n",
    "        while True:  # Adjust the limit as needed\n",
    "            results = client.get(\"r8kw-7aab\", limit=5000, offset=offset, where=where, select=select)\n",
    "            if not results:  # Break if no more data is returned\n",
    "                break\n",
    "            all_results.extend(results)\n",
    "            offset += 5000  # Increment the offset for the next chunk\n",
    "\n",
    "        results_df = pd.DataFrame.from_records(all_results)\n",
    "        return results_df\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e21b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = getCdcData( select=\"start_date, end_date,  mmwr_week, state, covid_19_deaths, total_deaths, pneumonia_deaths, pneumonia_and_covid_19_deaths, influenza_deaths,pneumonia_influenza_or_covid_19_deaths\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8342f1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    start_date                 end_date mmwr_week  \\\n",
      "0      2019-12-29T00:00:00.000  2020-01-04T00:00:00.000         1   \n",
      "1      2020-01-05T00:00:00.000  2020-01-11T00:00:00.000         2   \n",
      "2      2020-01-12T00:00:00.000  2020-01-18T00:00:00.000         3   \n",
      "3      2020-01-19T00:00:00.000  2020-01-25T00:00:00.000         4   \n",
      "4      2020-01-26T00:00:00.000  2020-02-01T00:00:00.000         5   \n",
      "...                        ...                      ...       ...   \n",
      "19381  2020-01-01T00:00:00.000  2025-06-21T00:00:00.000       NaN   \n",
      "19382  2020-01-01T00:00:00.000  2025-06-21T00:00:00.000       NaN   \n",
      "19383  2020-01-01T00:00:00.000  2025-06-21T00:00:00.000       NaN   \n",
      "19384  2020-01-01T00:00:00.000  2025-06-21T00:00:00.000       NaN   \n",
      "19385  2020-01-01T00:00:00.000  2025-06-21T00:00:00.000       NaN   \n",
      "\n",
      "               state covid_19_deaths total_deaths pneumonia_deaths  \\\n",
      "0      United States               0        60170             4111   \n",
      "1      United States               1        60734             4153   \n",
      "2      United States               2        59362             4066   \n",
      "3      United States               3        59162             3915   \n",
      "4      United States               0        58834             3818   \n",
      "...              ...             ...          ...              ...   \n",
      "19381     Washington           16707       363203            26313   \n",
      "19382  West Virginia            9067       141122            14237   \n",
      "19383      Wisconsin           18577       324837            19337   \n",
      "19384        Wyoming            2020        29661             2357   \n",
      "19385    Puerto Rico            7307       183606            25605   \n",
      "\n",
      "      pneumonia_and_covid_19_deaths influenza_deaths  \\\n",
      "0                                 0              434   \n",
      "1                                 1              475   \n",
      "2                                 2              468   \n",
      "3                                 0              500   \n",
      "4                                 0              481   \n",
      "...                             ...              ...   \n",
      "19381                          9548             1185   \n",
      "19382                          4580              509   \n",
      "19383                          6526              975   \n",
      "19384                          1028               94   \n",
      "19385                          5013              642   \n",
      "\n",
      "      pneumonia_influenza_or_covid_19_deaths  \n",
      "0                                       4545  \n",
      "1                                       4628  \n",
      "2                                       4534  \n",
      "3                                       4418  \n",
      "4                                       4299  \n",
      "...                                      ...  \n",
      "19381                                  34610  \n",
      "19382                                  19212  \n",
      "19383                                  32312  \n",
      "19384                                   3437  \n",
      "19385                                  28478  \n",
      "\n",
      "[19386 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb83dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_week=df[df['mmwr_week']>='1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6c4b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_week_us=df_week[df_week['state']=='United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37d86048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  start_date                 end_date mmwr_week  \\\n",
      "0    2019-12-29T00:00:00.000  2020-01-04T00:00:00.000         1   \n",
      "1    2020-01-05T00:00:00.000  2020-01-11T00:00:00.000         2   \n",
      "2    2020-01-12T00:00:00.000  2020-01-18T00:00:00.000         3   \n",
      "3    2020-01-19T00:00:00.000  2020-01-25T00:00:00.000         4   \n",
      "4    2020-01-26T00:00:00.000  2020-02-01T00:00:00.000         5   \n",
      "..                       ...                      ...       ...   \n",
      "281  2025-05-18T00:00:00.000  2025-05-24T00:00:00.000        21   \n",
      "282  2025-05-25T00:00:00.000  2025-05-31T00:00:00.000        22   \n",
      "283  2025-06-01T00:00:00.000  2025-06-07T00:00:00.000        23   \n",
      "284  2025-06-08T00:00:00.000  2025-06-14T00:00:00.000        24   \n",
      "285  2025-06-15T00:00:00.000  2025-06-21T00:00:00.000        25   \n",
      "\n",
      "             state covid_19_deaths total_deaths pneumonia_deaths  \\\n",
      "0    United States               0        60170             4111   \n",
      "1    United States               1        60734             4153   \n",
      "2    United States               2        59362             4066   \n",
      "3    United States               3        59162             3915   \n",
      "4    United States               0        58834             3818   \n",
      "..             ...             ...          ...              ...   \n",
      "281  United States             188        53873             2916   \n",
      "282  United States             194        51838             2871   \n",
      "283  United States             165        47872             2704   \n",
      "284  United States             116        39055             2070   \n",
      "285  United States              70        21814             1112   \n",
      "\n",
      "    pneumonia_and_covid_19_deaths influenza_deaths  \\\n",
      "0                               0              434   \n",
      "1                               1              475   \n",
      "2                               2              468   \n",
      "3                               0              500   \n",
      "4                               0              481   \n",
      "..                            ...              ...   \n",
      "281                            83               42   \n",
      "282                            77               53   \n",
      "283                            67               34   \n",
      "284                            51               37   \n",
      "285                            25               14   \n",
      "\n",
      "    pneumonia_influenza_or_covid_19_deaths  \n",
      "0                                     4545  \n",
      "1                                     4628  \n",
      "2                                     4534  \n",
      "3                                     4418  \n",
      "4                                     4299  \n",
      "..                                     ...  \n",
      "281                                   3061  \n",
      "282                                   3036  \n",
      "283                                   2836  \n",
      "284                                   2170  \n",
      "285                                   1171  \n",
      "\n",
      "[286 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_week_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d050f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_week_us[['start_date', 'end_date', 'mmwr_week',  'pneumonia_deaths' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c770fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  start_date                 end_date mmwr_week  \\\n",
      "0    2019-12-29T00:00:00.000  2020-01-04T00:00:00.000         1   \n",
      "1    2020-01-05T00:00:00.000  2020-01-11T00:00:00.000         2   \n",
      "2    2020-01-12T00:00:00.000  2020-01-18T00:00:00.000         3   \n",
      "3    2020-01-19T00:00:00.000  2020-01-25T00:00:00.000         4   \n",
      "4    2020-01-26T00:00:00.000  2020-02-01T00:00:00.000         5   \n",
      "..                       ...                      ...       ...   \n",
      "281  2025-05-18T00:00:00.000  2025-05-24T00:00:00.000        21   \n",
      "282  2025-05-25T00:00:00.000  2025-05-31T00:00:00.000        22   \n",
      "283  2025-06-01T00:00:00.000  2025-06-07T00:00:00.000        23   \n",
      "284  2025-06-08T00:00:00.000  2025-06-14T00:00:00.000        24   \n",
      "285  2025-06-15T00:00:00.000  2025-06-21T00:00:00.000        25   \n",
      "\n",
      "    pneumonia_deaths  \n",
      "0               4111  \n",
      "1               4153  \n",
      "2               4066  \n",
      "3               3915  \n",
      "4               3818  \n",
      "..               ...  \n",
      "281             2916  \n",
      "282             2871  \n",
      "283             2704  \n",
      "284             2070  \n",
      "285             1112  \n",
      "\n",
      "[286 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "063f6548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taohe\\miniconda3\\envs\\epysurv-dev\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\Users\\taohe\\miniconda3\\envs\\epysurv-dev\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 转换为 datetime 类型\n",
    "df[\"start_date\"] = pd.to_datetime(df[\"start_date\"])\n",
    "df[\"end_date\"] = pd.to_datetime(df[\"end_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84f2047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置 index 为每周开始时间（推荐）\n",
    "df = df.set_index(\"start_date\")\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c8185e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-12-29', '2020-01-05', '2020-01-12', '2020-01-19',\n",
      "               '2020-01-26', '2020-02-02', '2020-02-09', '2020-02-16',\n",
      "               '2020-02-23', '2020-03-01',\n",
      "               ...\n",
      "               '2025-04-13', '2025-04-20', '2025-04-27', '2025-05-04',\n",
      "               '2025-05-11', '2025-05-18', '2025-05-25', '2025-06-01',\n",
      "               '2025-06-08', '2025-06-15'],\n",
      "              dtype='datetime64[ns]', name='start_date', length=286, freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5770f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"pneumonia_deaths\": \"n_cases\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b092a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"n_cases\"] = df[\"n_cases\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1f62eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_outbreak_cases'] = df['n_cases'].apply(lambda x: 0 if x <= 1000 else x - 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1db3e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.date_range(start=df.index[0], periods=len(df), freq='W-SUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "39bca5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-12-29', '2020-01-05', '2020-01-12', '2020-01-19',\n",
      "               '2020-01-26', '2020-02-02', '2020-02-09', '2020-02-16',\n",
      "               '2020-02-23', '2020-03-01',\n",
      "               ...\n",
      "               '2025-04-13', '2025-04-20', '2025-04-27', '2025-05-04',\n",
      "               '2025-05-11', '2025-05-18', '2025-05-25', '2025-06-01',\n",
      "               '2025-06-08', '2025-06-15'],\n",
      "              dtype='datetime64[ns]', length=286, freq='W-SUN')\n"
     ]
    }
   ],
   "source": [
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e301820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end_date= \"2024-12-30\" \n",
    "test_end_date=\"2025-01-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2e981b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用 train/test date 训练\n",
    "train = df.loc[:train_end_date, ['n_cases', 'n_outbreak_cases']].copy()\n",
    "test = df.loc[train_end_date:, ['n_cases', 'n_outbreak_cases']].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "77da9710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing weeks in train: DatetimeIndex([], dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "expected_index = pd.date_range(start=train.index[0], end=train.index[-1], freq='W-SUN')\n",
    "missing = expected_index.difference(train.index)\n",
    "print(\"Missing weeks in train:\", missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d05b215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing weeks in test: DatetimeIndex([], dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "expected_index = pd.date_range(start=test.index[0], end=test.index[-1], freq='W-SUN')\n",
    "missing = expected_index.difference(test.index)\n",
    "print(\"Missing weeks in test:\", missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "102a0b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-12-29', '2020-01-05', '2020-01-12', '2020-01-19',\n",
      "               '2020-01-26', '2020-02-02', '2020-02-09', '2020-02-16',\n",
      "               '2020-02-23', '2020-03-01',\n",
      "               ...\n",
      "               '2024-10-27', '2024-11-03', '2024-11-10', '2024-11-17',\n",
      "               '2024-11-24', '2024-12-01', '2024-12-08', '2024-12-15',\n",
      "               '2024-12-22', '2024-12-29'],\n",
      "              dtype='datetime64[ns]', length=262, freq='W-SUN')\n"
     ]
    }
   ],
   "source": [
    "print(expected_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "83c52cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FarringtonFlexible(years_back=3, window_half_width=3, reweight=True, weights_threshold=2.58, alpha=0.05, trend=True, trend_threshold=0.05, past_period_cutoff=4, min_cases_in_past_periods=5, power_transform='2/3', past_weeks_not_included=26, threshold_method='delta')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FarringtonFlexible(alpha=0.05, years_back=3)\n",
    "model.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f59c4d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-12-29', '2020-01-05', '2020-01-12', '2020-01-19',\n",
      "               '2020-01-26', '2020-02-02', '2020-02-09', '2020-02-16',\n",
      "               '2020-02-23', '2020-03-01',\n",
      "               ...\n",
      "               '2024-10-27', '2024-11-03', '2024-11-10', '2024-11-17',\n",
      "               '2024-11-24', '2024-12-01', '2024-12-08', '2024-12-15',\n",
      "               '2024-12-22', '2024-12-29'],\n",
      "              dtype='datetime64[ns]', length=262, freq='W-SUN')\n"
     ]
    }
   ],
   "source": [
    "print(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "af6ff9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred frequency: W-SUN\n"
     ]
    }
   ],
   "source": [
    "print(\"Inferred frequency:\", pd.infer_freq(test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "59148537",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = (\n",
    "            pd.concat((train, test), keys=[\"train\", \"test\"], sort=True)\n",
    "            .reset_index(level=0)\n",
    "            .rename(columns={\"level_0\": \"provenance\"})\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bf557158",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=pd.concat((train, test), keys=[\"train\", \"test\"], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "89b710c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2=d1.reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "94057922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-12-29', '2020-01-05', '2020-01-12', '2020-01-19',\n",
      "               '2020-01-26', '2020-02-02', '2020-02-09', '2020-02-16',\n",
      "               '2020-02-23', '2020-03-01',\n",
      "               ...\n",
      "               '2025-04-13', '2025-04-20', '2025-04-27', '2025-05-04',\n",
      "               '2025-05-11', '2025-05-18', '2025-05-25', '2025-06-01',\n",
      "               '2025-06-08', '2025-06-15'],\n",
      "              dtype='datetime64[ns]', length=286, freq='W-SUN')\n"
     ]
    }
   ],
   "source": [
    "print(full_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b8cd4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_data.index.freq is None:\n",
    "    freq = pd.infer_freq(full_data.index)\n",
    "    print(\"Inferred frequency:\", freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8c2addfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Add provenance column manually before concat\n",
    "train_ = train.copy()\n",
    "train_[\"provenance\"] = \"train\"\n",
    "\n",
    "test_ = test.copy()\n",
    "test_[\"provenance\"] = \"test\"\n",
    "\n",
    "# Step 2: Concatenate directly along axis=0 (row-wise), keep original index\n",
    "full_data = pd.concat([train_, test_], axis=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "661987eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2025-01-12', '2025-01-19', '2025-01-26', '2025-02-02',\n",
      "               '2025-02-09', '2025-02-16', '2025-02-23', '2025-03-02',\n",
      "               '2025-03-09', '2025-03-16', '2025-03-23', '2025-03-30',\n",
      "               '2025-04-06', '2025-04-13', '2025-04-20', '2025-04-27',\n",
      "               '2025-05-04', '2025-05-11', '2025-05-18', '2025-05-25',\n",
      "               '2025-06-01', '2025-06-08', '2025-06-15'],\n",
      "              dtype='datetime64[ns]', freq='W-SUN')\n"
     ]
    }
   ],
   "source": [
    "print(test_.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c042c272",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The time series index has no valid frequency. Index=DatetimeIndex(['2019-12-29', '2020-01-05', '2020-01-12', '2020-01-19',\n               '2020-01-26', '2020-02-02', '2020-02-09', '2020-02-16',\n               '2020-02-23', '2020-03-01',\n               ...\n               '2025-04-13', '2025-04-20', '2025-04-27', '2025-05-04',\n               '2025-05-11', '2025-05-18', '2025-05-25', '2025-06-01',\n               '2025-06-08', '2025-06-15'],\n              dtype='datetime64[ns]', length=285, freq=None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-82c4f2e9fa53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\taohe\\miniconda3\\envs\\epysurv-dev\\lib\\site-packages\\epysurv\\models\\timepoint\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"level_0\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"provenance\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         )\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0mr_instance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_r_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[1;31m# R indexes are 1-based. Therefore we add 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         detection_range = robjects.IntVector(\n",
      "\u001b[1;32mc:\\Users\\taohe\\miniconda3\\envs\\epysurv-dev\\lib\\site-packages\\epysurv\\models\\timepoint\\_base.py\u001b[0m in \u001b[0;36m_prepare_r_instance\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfreq\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                 raise ValueError(\n\u001b[1;32m--> 175\u001b[1;33m                     \u001b[1;34mf\"The time series index has no valid frequency. Index={data.index}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m                 )\n\u001b[0;32m    177\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The time series index has no valid frequency. Index=DatetimeIndex(['2019-12-29', '2020-01-05', '2020-01-12', '2020-01-19',\n               '2020-01-26', '2020-02-02', '2020-02-09', '2020-02-16',\n               '2020-02-23', '2020-03-01',\n               ...\n               '2025-04-13', '2025-04-20', '2025-04-27', '2025-05-04',\n               '2025-05-11', '2025-05-18', '2025-05-25', '2025-06-01',\n               '2025-06-08', '2025-06-15'],\n              dtype='datetime64[ns]', length=285, freq=None)"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1bca05da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def run_farrington_model(df, train_split_ratio=0.8, alpha=0.05, years_back=1):\n",
    "    \"\"\"\n",
    "    Trains the FarringtonFlexible model and generates predictions.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input data with DatetimeIndex and 'n_cases' column.\n",
    "        train_split_ratio (float): Proportion of data for training.\n",
    "        alpha (float): Significance level.\n",
    "        years_back (int): Years for baseline reference.\n",
    "\n",
    "    Returns:\n",
    "        df_full (pd.DataFrame): Original dataframe with expected and threshold values.\n",
    "        predictions (pd.DataFrame): Model predictions, including 'alarm' and 'upperbound'.\n",
    "        train (pd.DataFrame): Training portion of the original data.\n",
    "    \"\"\"\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"Input DataFrame must have a DatetimeIndex.\")\n",
    "    if 'n_cases' not in df.columns:\n",
    "        raise ValueError(\"Input DataFrame must contain an 'n_cases' column.\")\n",
    "    if not (0 < train_split_ratio < 1):\n",
    "        raise ValueError(\"train_split_ratio must be between 0 and 1 (exclusive).\")\n",
    "\n",
    "    train_size = int(len(df) * train_split_ratio)\n",
    "    if train_size == 0 or train_size == len(df):\n",
    "        raise ValueError(\"Data size or train_split_ratio results in empty train/test set.\")\n",
    "\n",
    "    train = df.iloc[:train_size].copy()\n",
    "    test = df.iloc[train_size:].copy()\n",
    "\n",
    "    model = FarringtonFlexible(alpha=alpha, years_back=years_back)\n",
    "    model.fit(train)\n",
    "    predictions = model.predict(test)\n",
    "\n",
    "    df_full = df.copy()\n",
    "    df_full['threshold'] = np.nan\n",
    "    df_full.loc[predictions.index, 'threshold'] = predictions['upperbound']\n",
    "    df_full['expected'] = train['n_cases'].mean()\n",
    "\n",
    "    return df_full, predictions, train\n",
    "\n",
    "def run_farrington_model_bydatesplit(df, train_end_date, test_end_date, alpha=0.05, years_back=1):\n",
    "    \"\"\"\n",
    "    Trains the FarringtonFlexible model and generates predictions.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input data with DatetimeIndex and 'n_cases' column.\n",
    "        train_end_date (str): End date for the training set (YYYY-MM-DD).\n",
    "        test_end_date (str): End date for the testing set (YYYY-MM-DD).\n",
    "        alpha (float): Significance level.\n",
    "        years_back (int): Years for baseline reference.\n",
    "\n",
    "    Returns:\n",
    "        df_full (pd.DataFrame): Original dataframe with expected and threshold values.\n",
    "        predictions (pd.DataFrame): Model predictions, including 'alarm' and 'upperbound'.\n",
    "        train (pd.DataFrame): Training portion of the original data.\n",
    "    \"\"\"\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"Input DataFrame must have a DatetimeIndex.\")\n",
    "    if 'n_cases' not in df.columns:\n",
    "        raise ValueError(\"Input DataFrame must contain an 'n_cases' column.\")\n",
    "    \n",
    "    # 用 train/test date 训练\n",
    "    train = df.loc[:train_end_date, ['n_cases', 'n_outbreak_cases']].copy()\n",
    "    test = df.loc[test_end_date:, ['n_cases', 'n_outbreak_cases']].copy()\n",
    "\n",
    "    model = FarringtonFlexible(alpha=alpha, years_back=years_back)\n",
    "    model.fit(train)\n",
    "    predictions = model.predict(test)\n",
    "\n",
    "    df_full = df.copy()\n",
    "    df_full['threshold'] = np.nan\n",
    "    df_full.loc[predictions.index, 'threshold'] = predictions['upperbound']\n",
    "    df_full['expected'] = train['n_cases'].mean()\n",
    "\n",
    "    return df_full, predictions, train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "864d29d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "df_full, predictions, train = run_farrington_model_bydatesplit(\n",
    "                    df,\n",
    "                    train_end_date=\"2024-12-30\",\n",
    "                    test_end_date=\"2025-01-05\",\n",
    "                    alpha=0.05,\n",
    "                    years_back=3\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b79f5d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用 2020-2024 训练\n",
    "# 用 train/test date 训练\n",
    "train = df.loc[:\"2024-12-30\", ['n_cases', 'n_outbreak_cases']].copy()\n",
    "test = df.loc[\"2025-01-05\":, ['n_cases', 'n_outbreak_cases']].copy()\n",
    "\n",
    "model = FarringtonFlexible(alpha=0.05, years_back=3)\n",
    "model.fit(train)\n",
    "predictions = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a990f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df.copy()\n",
    "df_full['threshold'] = np.nan\n",
    "df_full.loc[predictions.index, 'threshold'] = predictions['upperbound']\n",
    "df_full['expected'] = train['n_cases'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a84e21ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taohe\\miniconda3\\envs\\epysurv-dev\\lib\\site-packages\\epysurv\\models\\timepoint\\_base.py:47: UserWarning: The column \"n_outbreak_cases\" is not present in input parameter `data`. \"n_cases\" is treated as if it contains no outbreaks.\n",
      "  'The column \"n_outbreak_cases\" is not present in input parameter `data`. '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FarringtonFlexible(years_back=3, window_half_width=3, reweight=True, weights_threshold=2.58, alpha=0.01, trend=True, trend_threshold=0.05, past_period_cutoff=4, min_cases_in_past_periods=5, power_transform='2/3', past_weeks_not_included=26, threshold_method='delta')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train.to_frame()\n",
    "model = FarringtonFlexible()\n",
    "model.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f6cc796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           n_cases\n",
      "start_date        \n",
      "2025-01-05    4660\n",
      "2025-01-12    4832\n",
      "2025-01-19    4742\n",
      "2025-01-26    4586\n",
      "2025-02-02    4739\n",
      "2025-02-09    4425\n",
      "2025-02-16    4537\n",
      "2025-02-23    4464\n",
      "2025-03-02    4232\n",
      "2025-03-09    4026\n",
      "2025-03-16    3780\n",
      "2025-03-23    3807\n",
      "2025-03-30    3498\n",
      "2025-04-06    3493\n",
      "2025-04-13    3485\n",
      "2025-04-20    3376\n",
      "2025-04-27    3247\n",
      "2025-05-04    3230\n",
      "2025-05-11    3039\n",
      "2025-05-18    2916\n",
      "2025-05-25    2871\n",
      "2025-06-01    2704\n",
      "2025-06-08    2070\n",
      "2025-06-15    1112\n"
     ]
    }
   ],
   "source": [
    "test_df = test.to_frame()\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d3f9b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_cases'] = df['n_cases'].astype(int)\n",
    "df['n_outbreak_cases'] = df['n_cases'].apply(lambda x: 0 if x <= 4000 else x - 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f21e13dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             end_date mmwr_week  n_cases  n_outbreak_cases\n",
      "start_date                                                \n",
      "2019-12-29 2020-01-04         1     4111               111\n",
      "2020-01-05 2020-01-11         2     4153               153\n",
      "2020-01-12 2020-01-18         3     4066                66\n",
      "2020-01-19 2020-01-25         4     3915                 0\n",
      "2020-01-26 2020-02-01         5     3818                 0\n",
      "...               ...       ...      ...               ...\n",
      "2025-05-18 2025-05-24        21     2916                 0\n",
      "2025-05-25 2025-05-31        22     2871                 0\n",
      "2025-06-01 2025-06-07        23     2704                 0\n",
      "2025-06-08 2025-06-14        24     2070                 0\n",
      "2025-06-15 2025-06-21        25     1112                 0\n",
      "\n",
      "[286 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3548303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot_from_data(df,\n",
    "                            save_path,\n",
    "                            train_split_ratio=0.8,\n",
    "                            alpha=0.05,\n",
    "                            years_back=1,\n",
    "                            plot_title='FarringtonFlexible Model: Case Detection Plot',\n",
    "                            xlabel='Date',\n",
    "                            ylabel='Number of Cases'):\n",
    "    \"\"\"\n",
    "    Trains a FarringtonFlexible model on the provided data, makes predictions,\n",
    "    and generates a plot visualizing the results, saving it to a file.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing the time series data.\n",
    "                               Must have a DateTimeIndex and a column named 'n_cases'.\n",
    "        save_path (str): The full path (including filename and extension, e.g., .png)\n",
    "                         where the plot image will be saved.\n",
    "        train_split_ratio (float): Proportion of the data to use for training (0 to 1).\n",
    "        alpha (float): Significance level for the Farrington model's threshold calculation.\n",
    "        years_back (int): Number of previous years' data to consider for the baseline\n",
    "                          in the Farrington model.\n",
    "        plot_title (str): Title for the generated plot.\n",
    "        xlabel (str): Label for the x-axis.\n",
    "        ylabel (str): Label for the y-axis.\n",
    "\n",
    "    Returns:\n",
    "        None: The function saves the plot to the specified file path.\n",
    "    \"\"\"\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"Input DataFrame must have a DatetimeIndex.\")\n",
    "    if 'n_cases' not in df.columns:\n",
    "        raise ValueError(\"Input DataFrame must contain an 'n_cases' column.\")\n",
    "    if not (0 < train_split_ratio < 1):\n",
    "        raise ValueError(\"train_split_ratio must be between 0 and 1 (exclusive).\")\n",
    "\n",
    "    df = df.sort_index()\n",
    "    # Split training and testing data\n",
    "    #train_size = int(len(df) * train_split_ratio)\n",
    "    #if train_size == 0 or train_size == len(df):\n",
    "    #    raise ValueError(\"Data size or train_split_ratio results in an empty train or test set.\")\n",
    "\n",
    "    #train = df.iloc[:train_size].copy()\n",
    "    #test = df.iloc[train_size:].copy()\n",
    "    # 用 2020-2024 训练\n",
    "    train = df.loc[:'2024-12-30', ['n_cases', 'n_outbreak_cases']].copy()\n",
    "    test = df.loc['2025-01-05':, ['n_cases', 'n_outbreak_cases']].copy()\n",
    "\n",
    "    print(f\"Splitting data: {len(train)} training points, {len(test)} testing points.\")\n",
    "\n",
    "    # Initialize and fit the FarringtonFlexible model\n",
    "\n",
    "\n",
    "\n",
    "    model = FarringtonFlexible(alpha=alpha, years_back=years_back)\n",
    "    print(\"Fitting FarringtonFlexible model...\")\n",
    "    model.fit(train)\n",
    "    print(\"Model fitting complete.\")\n",
    "\n",
    "    # Predict on the test set\n",
    "    print(\"Making predictions...\")\n",
    "    predictions = model.predict(test)\n",
    "    print(\"Predictions complete.\")\n",
    "    # print(\"Prediction Columns:\", predictions.columns) # Optional: for debugging\n",
    "\n",
    "    # Prepare data for visualization\n",
    "    df_full = df.copy()\n",
    "\n",
    "    # Add threshold column - only for the test period where predictions exist\n",
    "    df_full['threshold'] = np.nan # Initialize with NaN\n",
    "    # Align prediction index with df_full index before assigning\n",
    "    common_index = predictions.index.intersection(df_full.index)\n",
    "    df_full.loc[common_index, 'threshold'] = predictions.loc[common_index, 'upperbound']\n",
    "\n",
    "    # Approximate expected cases using the mean of the training data\n",
    "    expected_value = train['n_cases'].mean()\n",
    "    df_full['expected'] = expected_value # Apply to the whole series for plotting continuity\n",
    "\n",
    "    # Create figure and axis objects\n",
    "    fig, ax = plt.subplots(figsize=(12, 6), dpi=300, constrained_layout=True)\n",
    "\n",
    "    # Plot actual cases\n",
    "    ax.plot(df_full.index, df_full['n_cases'], label='Actual Cases', color='blue', marker='o', markersize=4, linestyle='-')\n",
    "\n",
    "    # Plot expected cases\n",
    "    ax.plot(df_full.index, df_full['expected'], label=f'Expected Cases (Train Mean = {expected_value:.2f})', color='green', linestyle='--')\n",
    "\n",
    "    # Plot threshold line\n",
    "    ax.plot(df_full.index, df_full['threshold'], label=f'Threshold (alpha={alpha})', color='red', linestyle='--')\n",
    "\n",
    "    # Fill between expected and threshold\n",
    "    fill_indices = df_full['threshold'].dropna().index\n",
    "    if not fill_indices.empty:\n",
    "        expected_for_fill = df_full.loc[fill_indices, 'expected']\n",
    "        threshold_for_fill = df_full.loc[fill_indices, 'threshold']\n",
    "        ax.fill_between(fill_indices, expected_for_fill, threshold_for_fill,\n",
    "                    where=threshold_for_fill >= expected_for_fill,\n",
    "                    color='red', alpha=0.1, label='Alert Zone')\n",
    "\n",
    "    # Highlight alarms\n",
    "    if 'alarm' in predictions.columns:\n",
    "        alarm_indices = predictions[predictions['alarm']].index\n",
    "        outliers = df_full.loc[alarm_indices]\n",
    "        if not outliers.empty:\n",
    "            ax.scatter(outliers.index, outliers['n_cases'], color='purple', label='Alarms', zorder=5, s=50)\n",
    "\n",
    "    # Set labels, title, legend\n",
    "    ax.set_title(plot_title, fontsize=14, pad=20)\n",
    "    ax.set_xlabel(xlabel, fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel(ylabel, fontsize=12, labelpad=10)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    # Legend 放在图内，防止出界\n",
    "    ax.legend(loc='upper left', fontsize=12)\n",
    "\n",
    "    # Adjust layout manually\n",
    "    #fig.subplots_adjust(top=0.9, bottom=0.12, left=0.1, right=0.95)\n",
    "\n",
    "    # Save directory\n",
    "    save_dir = os.path.dirname(save_path)\n",
    "    if save_dir and not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        print(f\"Created directory: {save_dir}\")\n",
    "\n",
    "    # Save plot\n",
    "    try:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches=\"tight\", pad_inches=0.2)\n",
    "        print(f\"Plot saved successfully to: {save_path}\")\n",
    "        print(\"Current figure size:\", fig.get_size_inches())\n",
    "        # fig.show()  # optional for debug\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving plot to {save_path}: {e}\")\n",
    "    finally:\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ffb52ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data: 262 training points, 24 testing points.\n",
      "Fitting FarringtonFlexible model...\n",
      "Model fitting complete.\n",
      "Making predictions...\n",
      "Predictions complete.\n",
      "Plot saved successfully to: farrington_cdc_plot.png\n",
      "Current figure size: [12.  6.]\n",
      "\n",
      "Example usage finished.\n"
     ]
    }
   ],
   "source": [
    "output_plot_path = 'farrington_cdc_plot.png'\n",
    "    # For a specific path like in the original example:\n",
    "    # output_plot_path = r'C:\\Users\\YourUser\\Documents\\YourFolder\\farrington_simulation_plot.png'\n",
    "    # Ensure the directory exists or the script has permission to create it.\n",
    "\n",
    "    # 3. Generate and save the plot using the simulated data\n",
    "try:\n",
    "        generate_plot_from_data(\n",
    "            df=df,\n",
    "            save_path=output_plot_path,\n",
    "            #train_split_ratio=0.75, # Example: changed ratio\n",
    "            plot_title='FarringtonFlexible Model: CDC Pneumonia Deaths',\n",
    "            xlabel='Date',\n",
    "            ylabel='Number of Cases',\n",
    "            alpha=0.05,\n",
    "            years_back=3\n",
    "        )\n",
    "except Exception as e:\n",
    "        print(f\"\\nAn error occurred during plot generation: {e}\")\n",
    "\n",
    "print(\"\\nExample usage finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epysurv-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
