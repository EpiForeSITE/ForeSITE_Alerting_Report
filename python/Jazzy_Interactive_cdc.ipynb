{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to .venv (Python 3.12.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taohe\\miniconda3\\envs\\epysurv-dev\\lib\\site-packages\\rpy2\\robjects\\pandas2ri.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from epysurv.models.timepoint import FarringtonFlexible\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import requests\n",
    "from sodapy import Socrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getCdcData(where=None, select=None):\n",
    "    try:\n",
    "        app_token=\"Wa9PucgUy1cHNJgzoTZwhg9AY\"\n",
    "        client = Socrata(\"data.cdc.gov\", app_token=app_token, timeout=120)\n",
    "        \n",
    "        all_results = []\n",
    "        offset = 0\n",
    "        while True:  # Adjust the limit as needed\n",
    "            results = client.get(\"vbim-akqf\", limit=5000, offset=offset, where=where, select=select)\n",
    "            if not results:  # Break if no more data is returned\n",
    "                break\n",
    "            all_results.extend(results)\n",
    "            offset += 5000  # Increment the offset for the next chunk\n",
    "\n",
    "        results_df = pd.DataFrame.from_records(all_results)\n",
    "        return results_df\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = getCdcData(where=\"cdc_case_earliest_dt >= '2020-12-01' and cdc_case_earliest_dt<= '2020-12-15' and current_status='Laboratory-confirmed case'\", select=\"cdc_case_earliest_dt\")\n",
    "df.to_csv(\"covid_cases_2020_12_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloang all 2020 COVID-19 tests, we will create a simulation history data from 2015-2019 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simulation_data(start_date='2015-01-01',\n",
    "                             end_date='2019-12-31',\n",
    "                             freq='D',\n",
    "                             lam=5,\n",
    "                             outbreak_threshold=10,\n",
    "                             seed=42):\n",
    "    \"\"\"\n",
    "    Generates simulated epidemiological case data.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): Start date for the time series (YYYY-MM-DD).\n",
    "        end_date (str): End date for the time series (YYYY-MM-DD).\n",
    "        freq (str): Frequency of data points (pandas frequency string, e.g., 'D' for daily).\n",
    "        lam (float): Lambda parameter for the Poisson distribution (average number of cases).\n",
    "        outbreak_threshold (int): Threshold above which cases are considered part of an 'outbreak'\n",
    "                                 for the 'n_outbreak_cases' calculation.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with dates as index and columns 'n_cases'\n",
    "                          and 'n_outbreak_cases'.\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Create date range\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq=freq)\n",
    "\n",
    "    # Generate case counts using Poisson distribution\n",
    "    n_cases = np.random.poisson(lam=lam, size=len(dates))\n",
    "    df = pd.DataFrame({'n_cases': n_cases}, index=dates)\n",
    "\n",
    "    # Add n_outbreak_cases column based on the threshold\n",
    "    df['n_outbreak_cases'] = df['n_cases'].apply(lambda x: max(0, x - outbreak_threshold))\n",
    "\n",
    "    print(f\"Generated simulation data from {start_date} to {end_date}.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated simulation data from 2015-01-01 to 2019-12-31.\n"
     ]
    }
   ],
   "source": [
    "simulated_data = generate_simulation_data(\n",
    "        start_date='2015-01-01',\n",
    "        end_date='2019-12-31',\n",
    "        lam=8,\n",
    "        outbreak_threshold=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            n_cases  n_outbreak_cases\n",
      "Date                                 \n",
      "2015-01-01        6                 0\n",
      "2015-01-02        7                 0\n",
      "2015-01-03        6                 0\n",
      "2015-01-04        7                 0\n",
      "2015-01-05        7                 0\n",
      "...             ...               ...\n",
      "2019-12-27        5                 0\n",
      "2019-12-28        9                 0\n",
      "2019-12-29       10                 0\n",
      "2019-12-30        9                 0\n",
      "2019-12-31        5                 0\n",
      "\n",
      "[1826 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(simulated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_data.index.name = 'Date'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we got the history data, we will add 2020 Covid-19 test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020 = pd.read_csv(\"covid_cases_2020_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             cdc_case_earliest_dt\n",
      "0         2020-01-01T00:00:00.000\n",
      "1         2020-01-01T00:00:00.000\n",
      "2         2020-01-01T00:00:00.000\n",
      "3         2020-01-01T00:00:00.000\n",
      "4         2020-01-01T00:00:00.000\n",
      "...                           ...\n",
      "14717094  2020-12-24T00:00:00.000\n",
      "14717095  2020-12-24T00:00:00.000\n",
      "14717096  2020-12-24T00:00:00.000\n",
      "14717097  2020-12-24T00:00:00.000\n",
      "14717098  2020-12-24T00:00:00.000\n",
      "\n",
      "[14717099 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the new CSV into a DataFrame\n",
    "df20_2 = pd.read_csv(\"covid_cases_2020_2.csv\")\n",
    "df20_31 = pd.read_csv(\"covid_cases_2020_3_1.csv\")\n",
    "df20_32 = pd.read_csv(\"covid_cases_2020_3_2.csv\")\n",
    "df20_41 = pd.read_csv(\"covid_cases_2020_4_1.csv\")\n",
    "df20_42 = pd.read_csv(\"covid_cases_2020_4_2.csv\")\n",
    "df20_51 = pd.read_csv(\"covid_cases_2020_5_1.csv\")\n",
    "df20_52 = pd.read_csv(\"covid_cases_2020_5_2.csv\")\n",
    "df20_61 = pd.read_csv(\"covid_cases_2020_6_1.csv\")\n",
    "df20_62 = pd.read_csv(\"covid_cases_2020_6_2.csv\")\n",
    "df20_63 = pd.read_csv(\"covid_cases_2020_6_3.csv\")\n",
    "df20_71 = pd.read_csv(\"covid_cases_2020_7_1.csv\")\n",
    "df20_72 = pd.read_csv(\"covid_cases_2020_7_2.csv\")\n",
    "df20_81 = pd.read_csv(\"covid_cases_2020_8_1.csv\")\n",
    "df20_82 = pd.read_csv(\"covid_cases_2020_8_2.csv\")\n",
    "df20_83 = pd.read_csv(\"covid_cases_2020_8_3.csv\")\n",
    "df20_91 = pd.read_csv(\"covid_cases_2020_9_1.csv\")\n",
    "df20_92 = pd.read_csv(\"covid_cases_2020_9_2.csv\")\n",
    "df20_101 = pd.read_csv(\"covid_cases_2020_10_1.csv\")\n",
    "df20_102 = pd.read_csv(\"covid_cases_2020_10_2.csv\")\n",
    "df20_111 = pd.read_csv(\"covid_cases_2020_11_1.csv\")\n",
    "df20_112 = pd.read_csv(\"covid_cases_2020_11_2.csv\")\n",
    "df20_113 = pd.read_csv(\"covid_cases_2020_11_3.csv\")\n",
    "df20_121 = pd.read_csv(\"covid_cases_2020_12_1.csv\")\n",
    "df20_122 = pd.read_csv(\"covid_cases_2020_12_2.csv\")\n",
    "df20_123 = pd.read_csv(\"covid_cases_2020_12_3.csv\")\n",
    "df20_124 = pd.read_csv(\"covid_cases_2020_12_4.csv\")\n",
    "\n",
    "\n",
    "# Combine with the existing df (stack rows)\n",
    "df2020 = pd.concat([df2020, df20_2, df20_31, df20_32, df20_41, df20_42, df20_51, df20_52, df20_61, \n",
    "                    df20_62, df20_63, df20_71, df20_72, df20_81, df20_82, df20_83, df20_91,df20_92,\n",
    "                    df20_101, df20_102, df20_111, df20_112, df20_121, df20_122, df20_123, df20_124\n",
    "                    ], ignore_index=True)\n",
    "print(df2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020['cdc_case_earliest_dt'] = pd.to_datetime(df2020['cdc_case_earliest_dt']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         cdc_case_earliest_dt\n",
      "0                  2020-01-01\n",
      "1                  2020-01-01\n",
      "2                  2020-01-01\n",
      "3                  2020-01-01\n",
      "4                  2020-01-01\n",
      "...                       ...\n",
      "14717094           2020-12-24\n",
      "14717095           2020-12-24\n",
      "14717096           2020-12-24\n",
      "14717097           2020-12-24\n",
      "14717098           2020-12-24\n",
      "\n",
      "[14717099 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the number of patients per date from cdc data\n",
    "cnt = df2020.groupby(\"cdc_case_earliest_dt\").size().rename(\"n_cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdc_case_earliest_dt\n",
      "2020-01-01    751\n",
      "2020-01-02    192\n",
      "2020-01-03    147\n",
      "2020-01-04    300\n",
      "2020-01-05    170\n",
      "Name: n_cases, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(cnt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdcdata=cnt.to_frame()\n",
    "cdcdata.index.name = 'Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            n_cases\n",
      "Date               \n",
      "2020-01-01      751\n",
      "2020-01-02      192\n",
      "2020-01-03      147\n",
      "2020-01-04      300\n",
      "2020-01-05      170\n",
      "...             ...\n",
      "2020-12-19   125877\n",
      "2020-12-21   192653\n",
      "2020-12-22   275849\n",
      "2020-12-23   172270\n",
      "2020-12-24   136421\n",
      "\n",
      "[337 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cdcdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdcdata['n_outbreak_cases'] = cdcdata['n_cases'].apply(lambda x: 0 if x <= 10 else x - 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([simulated_data,cdcdata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     n_cases  n_outbreak_cases\n",
      "Date                                          \n",
      "2015-01-01 00:00:00        6                 0\n",
      "2015-01-02 00:00:00        7                 0\n",
      "2015-01-03 00:00:00        6                 0\n",
      "2015-01-04 00:00:00        7                 0\n",
      "2015-01-05 00:00:00        7                 0\n",
      "...                      ...               ...\n",
      "2020-12-19            125877            125867\n",
      "2020-12-21            192653            192643\n",
      "2020-12-22            275849            275839\n",
      "2020-12-23            172270            172260\n",
      "2020-12-24            136421            136411\n",
      "\n",
      "[2163 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            n_cases  n_outbreak_cases\n",
      "2015-01-01        6                 0\n",
      "2015-01-02        7                 0\n",
      "2015-01-03        6                 0\n",
      "2015-01-04        7                 0\n",
      "2015-01-05        7                 0\n",
      "...             ...               ...\n",
      "2020-12-19   125877            125867\n",
      "2020-12-21   192653            192643\n",
      "2020-12-22   275849            275839\n",
      "2020-12-23   172270            172260\n",
      "2020-12-24   136421            136411\n",
      "\n",
      "[2163 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to DatetimeIndex\n",
    "data.index = pd.to_datetime(data.index)\n",
    "#Extract date-only (converts to Python date objects)\n",
    "#data.index = data.index.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2020-12-13', '2020-12-14', '2020-12-16', '2020-12-17',\n",
      "               '2020-12-18', '2020-12-19', '2020-12-21', '2020-12-22',\n",
      "               '2020-12-23', '2020-12-24'],\n",
      "              dtype='datetime64[ns]', length=2163, freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complete date range (daily frequency)\n",
    "full_date_range = pd.date_range(start=data.index.min(), end=data.index.max(), freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.reindex(full_date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Fill missing values (choose one based on your needs)\n",
    "# - Fill with NaN (default, no action needed)\n",
    "#df['n_cases'] = df['n_cases']  # Already NaN for missing dates\n",
    "# - Fill with 0\n",
    "df['n_cases'] = df['n_cases'].fillna(0)\n",
    "df['n_outbreak_cases'] = df['n_outbreak_cases'].fillna(0)\n",
    "# - Forward fill\n",
    "# df['n_cases'] = df['n_cases'].fillna(method='ffill')\n",
    "# - Linear interpolation\n",
    "# df['n_cases'] = df['n_cases'].interpolate()\n",
    "\n",
    "# Set index name (optional)\n",
    "df.index.name = 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_cases'] = df['n_cases'].astype(int)\n",
    "df['n_outbreak_cases'] = df['n_outbreak_cases'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            n_cases  n_outbreak_cases\n",
      "date                                 \n",
      "2015-01-01        6                 0\n",
      "2015-01-02        7                 0\n",
      "2015-01-03        6                 0\n",
      "2015-01-04        7                 0\n",
      "2015-01-05        7                 0\n",
      "...             ...               ...\n",
      "2020-12-20        0                 0\n",
      "2020-12-21   192653            192643\n",
      "2020-12-22   275849            275839\n",
      "2020-12-23   172270            172260\n",
      "2020-12-24   136421            136411\n",
      "\n",
      "[2185 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"local_covid_19_test_data.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020 = pd.read_csv(\"local_covid_19_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date  n_cases  n_outbreak_cases\n",
      "0     2015-01-01        6                 0\n",
      "1     2015-01-02        7                 0\n",
      "2     2015-01-03        6                 0\n",
      "3     2015-01-04        7                 0\n",
      "4     2015-01-05        7                 0\n",
      "...          ...      ...               ...\n",
      "2180  2020-12-20        0                 0\n",
      "2181  2020-12-21   192653            192643\n",
      "2182  2020-12-22   275849            275839\n",
      "2183  2020-12-23   172270            172260\n",
      "2184  2020-12-24   136421            136411\n",
      "\n",
      "[2185 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020['date'] = pd.to_datetime(df2020['date'])  # Ensure 'date' is datetime type\n",
    "df2020 = df2020.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2020-12-15', '2020-12-16', '2020-12-17', '2020-12-18',\n",
      "               '2020-12-19', '2020-12-20', '2020-12-21', '2020-12-22',\n",
      "               '2020-12-23', '2020-12-24'],\n",
      "              dtype='datetime64[ns]', name='date', length=2185, freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(df2020.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot_from_data(df,\n",
    "                            save_path,\n",
    "                            train_split_ratio=0.8,\n",
    "                            alpha=0.05,\n",
    "                            years_back=1,\n",
    "                            plot_title='FarringtonFlexible Model: Case Detection Plot',\n",
    "                            xlabel='Date',\n",
    "                            ylabel='Number of Cases'):\n",
    "    \"\"\"\n",
    "    Trains a FarringtonFlexible model on the provided data, makes predictions,\n",
    "    and generates a plot visualizing the results, saving it to a file.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing the time series data.\n",
    "                               Must have a DateTimeIndex and a column named 'n_cases'.\n",
    "        save_path (str): The full path (including filename and extension, e.g., .png)\n",
    "                         where the plot image will be saved.\n",
    "        train_split_ratio (float): Proportion of the data to use for training (0 to 1).\n",
    "        alpha (float): Significance level for the Farrington model's threshold calculation.\n",
    "        years_back (int): Number of previous years' data to consider for the baseline\n",
    "                          in the Farrington model.\n",
    "        plot_title (str): Title for the generated plot.\n",
    "        xlabel (str): Label for the x-axis.\n",
    "        ylabel (str): Label for the y-axis.\n",
    "\n",
    "    Returns:\n",
    "        None: The function saves the plot to the specified file path.\n",
    "    \"\"\"\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"Input DataFrame must have a DatetimeIndex.\")\n",
    "    if 'n_cases' not in df.columns:\n",
    "        raise ValueError(\"Input DataFrame must contain an 'n_cases' column.\")\n",
    "    if not (0 < train_split_ratio < 1):\n",
    "        raise ValueError(\"train_split_ratio must be between 0 and 1 (exclusive).\")\n",
    "\n",
    "    # Split training and testing data\n",
    "    train_size = int(len(df) * train_split_ratio)\n",
    "    if train_size == 0 or train_size == len(df):\n",
    "        raise ValueError(\"Data size or train_split_ratio results in an empty train or test set.\")\n",
    "\n",
    "    train = df.iloc[:train_size].copy()\n",
    "    test = df.iloc[train_size:].copy()\n",
    "\n",
    "    print(f\"Splitting data: {len(train)} training points, {len(test)} testing points.\")\n",
    "\n",
    "    # Initialize and fit the FarringtonFlexible model\n",
    "    \n",
    "\n",
    "\n",
    "    model = FarringtonFlexible(alpha=alpha, years_back=years_back)\n",
    "    print(\"Fitting FarringtonFlexible model...\")\n",
    "    model.fit(train)\n",
    "    print(\"Model fitting complete.\")\n",
    "\n",
    "    # Predict on the test set\n",
    "    print(\"Making predictions...\")\n",
    "    predictions = model.predict(test)\n",
    "    print(\"Predictions complete.\")\n",
    "    # print(\"Prediction Columns:\", predictions.columns) # Optional: for debugging\n",
    "\n",
    "    # Prepare data for visualization\n",
    "    df_full = df.copy()\n",
    "\n",
    "    # Add threshold column - only for the test period where predictions exist\n",
    "    df_full['threshold'] = np.nan # Initialize with NaN\n",
    "    # Align prediction index with df_full index before assigning\n",
    "    common_index = predictions.index.intersection(df_full.index)\n",
    "    df_full.loc[common_index, 'threshold'] = predictions.loc[common_index, 'upperbound']\n",
    "\n",
    "    # Approximate expected cases using the mean of the training data\n",
    "    expected_value = train['n_cases'].mean()\n",
    "    df_full['expected'] = expected_value # Apply to the whole series for plotting continuity\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot actual cases\n",
    "    plt.plot(df_full.index, df_full['n_cases'], label='Actual Cases', color='blue', marker='o', markersize=4, linestyle='-')\n",
    "\n",
    "    # Plot expected cases\n",
    "    plt.plot(df_full.index, df_full['expected'], label=f'Expected Cases (Train Mean = {expected_value:.2f})', color='green', linestyle='--')\n",
    "\n",
    "    # Plot threshold line (only where it exists - test period)\n",
    "    plt.plot(df_full.index, df_full['threshold'], label=f'Threshold (alpha={alpha})', color='red', linestyle='--')\n",
    "\n",
    "    # Fill the alert zone (between expected and threshold, only in the test period)\n",
    "    # Ensure we only fill where threshold is not NaN\n",
    "    fill_indices = df_full['threshold'].dropna().index\n",
    "    if not fill_indices.empty:\n",
    "         # Ensure 'expected' values are available for these indices\n",
    "        expected_for_fill = df_full.loc[fill_indices, 'expected']\n",
    "        threshold_for_fill = df_full.loc[fill_indices, 'threshold']\n",
    "        plt.fill_between(fill_indices, expected_for_fill, threshold_for_fill,\n",
    "                         where=threshold_for_fill >= expected_for_fill, # Only fill where threshold > expected\n",
    "                         color='red', alpha=0.1, label='Alert Zone')\n",
    "\n",
    "    # Highlight outliers/alarms found in the prediction period\n",
    "    if 'alarm' in predictions.columns:\n",
    "        alarm_indices = predictions[predictions['alarm']].index\n",
    "        outliers = df_full.loc[alarm_indices]\n",
    "        if not outliers.empty:\n",
    "            plt.scatter(outliers.index, outliers['n_cases'], color='purple', label='Alarms', zorder=5, s=50) # Increased size\n",
    "\n",
    "    # Add plot elements\n",
    "    plt.legend()\n",
    "    plt.title(plot_title, fontsize=14)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Ensure the save directory exists\n",
    "    save_dir = os.path.dirname(save_path)\n",
    "    if save_dir and not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        print(f\"Created directory: {save_dir}\")\n",
    "\n",
    "    # Save the plot\n",
    "    try:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved successfully to: {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving plot to {save_path}: {e}\")\n",
    "    finally:\n",
    "        plt.close() # Close the plot to free memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data: 1638 training points, 547 testing points.\n",
      "Fitting FarringtonFlexible model...\n",
      "Model fitting complete.\n",
      "Making predictions...\n",
      "Predictions complete.\n",
      "Plot saved successfully to: farrington_covidtest_plot.png\n",
      "\n",
      "Example usage finished.\n"
     ]
    }
   ],
   "source": [
    "output_plot_path = 'farrington_covidtest_plot.png'\n",
    "    # For a specific path like in the original example:\n",
    "    # output_plot_path = r'C:\\Users\\YourUser\\Documents\\YourFolder\\farrington_simulation_plot.png'\n",
    "    # Ensure the directory exists or the script has permission to create it.\n",
    "\n",
    "    # 3. Generate and save the plot using the simulated data\n",
    "try:\n",
    "        generate_plot_from_data(\n",
    "            df=df2020,\n",
    "            save_path=output_plot_path,\n",
    "            train_split_ratio=0.75, # Example: changed ratio\n",
    "            alpha=0.05,\n",
    "            years_back=3\n",
    "        )\n",
    "except Exception as e:\n",
    "        print(f\"\\nAn error occurred during plot generation: {e}\")\n",
    "\n",
    "print(\"\\nExample usage finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            n_cases  n_outbreak_cases\n",
      "date                                 \n",
      "2015-01-01        6                 0\n",
      "2015-01-02        7                 0\n",
      "2015-01-03        6                 0\n",
      "2015-01-04        7                 0\n",
      "2015-01-05        7                 0\n",
      "...             ...               ...\n",
      "2020-12-20        0                 0\n",
      "2020-12-21   192653            192643\n",
      "2020-12-22   275849            275839\n",
      "2020-12-23   172270            172260\n",
      "2020-12-24   136421            136411\n",
      "\n",
      "[2185 rows x 2 columns]\n",
      "Splitting data: 1638 training points, 547 testing points.\n",
      "Fitting FarringtonFlexible model...\n",
      "Model fitting complete.\n",
      "Making predictions...\n",
      "Predictions complete.\n",
      "Plot saved successfully to: output_plot_path.png\n"
     ]
    }
   ],
   "source": [
    "df2020 = pd.read_csv(\"local_covid_19_test_data.csv\")\n",
    "df2020['date'] = pd.to_datetime(df2020['date'])  # Ensure 'date' is datetime type\n",
    "df2020 = df2020.set_index('date')\n",
    "print(df2020)\n",
    "generate_plot_from_data(\n",
    "                df=df2020,\n",
    "                save_path=\"output_plot_path.png\",\n",
    "                train_split_ratio=0.75,\n",
    "                alpha=0.05,\n",
    "                years_back=3,\n",
    "                plot_title=\"title\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateOutbreak(df: pd.DataFrame, threshold: int = 10):\n",
    "    if df is None:\n",
    "        print(\"No data :( [calculate outbreak]\")\n",
    "        return None\n",
    "    if \"NumPatients\" in df.columns:\n",
    "        outbreak = df[\"NumPatients\"].apply(lambda x: 0 if x <= threshold else x - 10)\n",
    "        df[\"numOutbreakPatients\"] = outbreak\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Column 'NumPatients' not found in the DataFrame.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteColumns(colToKeep: str, df: pd.DataFrame):\n",
    "    #deletes all columns but the date column\n",
    "    if df is not None:\n",
    "        df = df[[colToKeep]]\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No data :( [delete columns]\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPatientCount(df: pd.DataFrame, dateCol: str):\n",
    "    if dateCol == None:\n",
    "        print(\"No date column provided. [patient count]\")\n",
    "        return None\n",
    "    if df is not None:\n",
    "        #rename to date\n",
    "        result = result.rename(columns={\n",
    "            dateCol : \"Date\",\n",
    "        })\n",
    "\n",
    "        #convert the date column to datetime\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors='coerce')\n",
    "\n",
    "        #get the number of patients per date\n",
    "        cnt = df.groupby(\"Date\").size().rename(\"NumPatients\")\n",
    "\n",
    "        #merge and drop duplicates\n",
    "        result = df.drop_duplicates(subset=\"Date\").merge(cnt, left_on=\"Date\", right_index=True)\n",
    "\n",
    "        #give df a full date range\n",
    "        result = result.set_index(\"Date\").resample(\"D\").first().reset_index()\n",
    "        result = result.fillna(0)\n",
    "\n",
    "        #order into chronological order\n",
    "        result = result.sort_values(by=\"Date\").reset_index(drop=True)\n",
    "\n",
    "        #change to int\n",
    "        result[\"NumPatients\"] = result[\"NumPatients\"].astype(int)\n",
    "\n",
    "        return result\n",
    "\n",
    "    else:\n",
    "        print(\"No data :( [patient count]\")\n",
    "        return None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epysurv-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
